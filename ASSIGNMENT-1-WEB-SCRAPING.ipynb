{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69942d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write a python program to display all the header tags from wikipedia.org\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "# # 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make data frame.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for index in range(0, len(movies)):\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for movie in list:\n",
    "    \n",
    "    print(movie['place'], '-', movie['movie_title'], '('+movie['year'],')','-', movie['rating'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('imdb_top__movies.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head(100)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "\n",
    "# # 3.Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list =[]\n",
    "\n",
    "\n",
    "\n",
    "for index in range(0, len(movies)):\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head(100)\n",
    "\n",
    "\n",
    "\n",
    "for movie in list:\n",
    "    print(movie['place'], '-', movie['movie_title'], '('+movie['year'],')','-', movie['rating'])\n",
    "    \n",
    "\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('imdb_top__movies.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head(100)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "# # 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scraped_formerPresidents = soup.find_all('div',class_='presidentListing')\n",
    "scraped_formerPresidents\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "formerPresidents = []\n",
    "for formerPresident in scraped_formerPresidents:\n",
    "    print(formerPresident.get_text())\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "# # 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# # 6.\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/women/team-rankings/odi')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# # 7.Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :i) Headline ii) Time iii) News Link\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for link in soup.findAll(\"a\"):\n",
    "    print(\"Headlines : {}\".format(link.text))\n",
    "\n",
    "\n",
    "\n",
    "for link in soup.findAll('time',{'class' : 'LatestNews-timestamp'}):\n",
    "    print(\"Times : {}\".format(link.text))\n",
    "\n",
    "\n",
    "\n",
    "cnbc_url=\"https://www.cnbc.com/world\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.cnbc.com/world')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "\n",
    "links_list = soup.find_all('a')\n",
    "\n",
    "\n",
    "\n",
    "for link in links_list:\n",
    "    if 'href'in link.attrs:\n",
    "        print(str(link.attrs['href']))\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "# # 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details : i) Paper Title ii) Authors iii) Published Date iv) Paper URL\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for link in soup.findAll(\"h2\"):\n",
    "    print(\"PaperTitle : {}\".format(link.text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "author = []\n",
    "\n",
    "for i in soup.find_all('span',{'class' : \"sc-1w3fpd7-0 pgLAT\"}):\n",
    "    author.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "author\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date = []\n",
    "\n",
    "for i in soup.find_all('span',{'class' : 'sc-1thf9ly-2 bKddwo'}):\n",
    "    date.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://www.journals.elsevier.com\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.journals.elsevier.com') \n",
    "page\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "links_list = soup.find_all('a')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for link in links_list:\n",
    "    if 'href'in link.attrs:\n",
    "        print(str(link.attrs['href']))\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "## 10) Write a python program to scrape the details of top publications from Google Scholar from \n",
    "#  https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "#  i) Rank \n",
    "#  ii) Publication\n",
    "#  iii) h5-index\n",
    "#  iv) h5-median\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "rank = []\n",
    "publication = []\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "rank\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "publication\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "citation = []\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_n\"):\n",
    "   citation.append(i.text)\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "citation\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "# # 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "# i) Restaurant name ii) Cuisine iii) Location iv) Ratings v) Image URL\n",
    "\n",
    "\n",
    "\n",
    "get_ipython().system('pip install bs4')\n",
    "get_ipython().system('pip install requests')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "\n",
    "\n",
    "# RESTAURANT NAME\n",
    "scraped_restaurant_name = soup.find_all('a',class_=\"restnt-name ellipsis\")\n",
    "scraped_restaurant_name\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "#EMPTY LIST\n",
    "restaurant_name = []\n",
    "\n",
    "#Restaurant name\n",
    "for rn in scraped_restaurant_name:\n",
    "    rn = rn.get_text().replace('\\n','')\n",
    "    restaurant_name.append(rn)\n",
    "restaurant_name\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "# Cuisine \n",
    "scraped_cuisines = soup.find_all('div',class_=\"filter-component-wrap cuisine-wrap\")\n",
    "scraped_cuisines\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "#EMPTY LIST\n",
    "cuisines = []\n",
    "\n",
    "#cuisines\n",
    "for c in scraped_cuisines:\n",
    "    c = c.get_text().replace('\\n',' ')\n",
    "cuisines.append(c)\n",
    "cuisines\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "# Location\n",
    "scraped_location = soup.find_all('div',class_=\"restnt-loc ellipsis\")\n",
    "scraped_location\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "#EMPTY LIST\n",
    "location = []\n",
    "\n",
    "#Location\n",
    "for l in scraped_location :\n",
    "    l = l.get_text().replace('\\n',' ')\n",
    "location.append(l)\n",
    "location\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "#Ratings\n",
    "scraped_ratings = soup.find_all('div',class_=\"restnt-rating rating-4\")\n",
    "scraped_ratings\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "\n",
    "#EMPTY LIST\n",
    "ratings = []\n",
    "\n",
    "#Location\n",
    "for r in scraped_ratings :\n",
    "    r = r.get_text().replace('\\n',' ')\n",
    "ratings.append(r)\n",
    "ratings\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "# Image URL\n",
    "scraped_image_url = soup.find_all('img',class_= \"no-img\")\n",
    "scraped_image_url\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "#EMPTY LIST\n",
    "image_url = []\n",
    "\n",
    "#Location\n",
    "for i in scraped_image_url :\n",
    "    i = i.get_text().replace('\\n',' ')\n",
    "image_url.append(i)\n",
    "image_url\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
